---
layout: post
author: nguyenthanhminh
title: Algorithm - Kalman Filter Part 2
---

# 1. Nh·∫Øc l·∫°i v·ªÅ Kalman Filter

M√¨nh s·∫Ω t√≥m t·∫Øt Kalman Filter d∆∞·ªõi d·∫°ng c√°c k√Ω hi·ªáu to√°n h·ªçc v√† kh√¥ng gi·∫£i th√≠ch nh∆∞ ph·∫ßn 1 n·ªØa, c√°c b·∫°n n·∫øu ch∆∞a hi·ªÉu r√µ c√≥ th·ªÉ quay l·∫°i [ph·∫ßn 1](https://think-man-blog.github.io/2022/10/09/Kalman_Filter_P1.html).

Kalman Filter g·ªìm c√°c th√†nh ph·∫ßn nh∆∞ sau:

$\mathbf{x}\in \mathbb{R}^{n}$ l√† tr·∫°ng th√°i c·ªßa object c√≥ k√®m theo y·∫øu t·ªë th·ªùi gian.

$ \mathbf{F} \in \mathbb{R}^{n*n}$ l√† m√¥ h√¨nh chuy·ªÉn ƒë·ªïi tr·∫°ng th√°i (The state-transition model). 

$$\mathbf{x}^{t+1} = \mathbf{F}*\mathbf{x}^{t} + \mathbf{w}^{t} \hspace{1cm} (1)$$ 

$\mathbf{w} \thicksim \mathcal{N}(0, \mathbf{Q}) \in \mathbb{R}^{n}$ l√† nhi·ªÖu c·ªßa d·ª± ƒëo√°n.

Ta xem $\mathbf{x} \thicksim \mathcal{N}(\overline{x}, \Sigma_{x})$. G·ªçi $\Sigma_{x}$ l√† ma tr·∫≠n covariance c·ªßa x k√®m y·∫øu t·ªë th·ªùi gian, v√† k·ª≥ v·ªçng l√† $\overline{x}$. 

$\mathbf{y}\in \mathbb{R}^{m}$ l√† quan s√°t c·ªßa object k√®m theo y·∫øu t·ªë th·ªùi gian.

$ \mathbf{H} \in \mathbb{R}^{m*n}$ l√† m√¥ h√¨nh quan s√°t (The observation model).

$$\mathbf{y}^{t} = \mathbf{H}*\mathbf{x}^{t} + \mathbf{v}^{t} \hspace{1cm} (2)$$

$\mathbf{v} \thicksim \mathcal{N}(0, \mathbf{R}) \in \mathbb{R}^{m}$ l√† nhi·ªÖu c·ªßa quan s√°t.

Ta xem $\mathbf{y} \thicksim \mathcal{N}(\overline{y}, \Sigma_{y})$. G·ªçi $\Sigma_{y}$ l√† ma tr·∫≠n covariance c·ªßa x k√®m y·∫øu t·ªë th·ªùi gian, v√† k·ª≥ v·ªçng l√† $\overline{y}$. 

Di·ªÖn gi·∫£i d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c d·∫´n t·ª´ [Thetalog](https://thetalog.com/machine-learning/kalman-filter/), m√¨nh khuy√™n c√°c b·∫°n c≈©ng n√™n ƒë·ªçc Thetalog ƒë·ªÉ c√≥ th·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ Kalman Filter.

Ta c√≥ gi·∫£ ƒë·ªãnh:

$$\mathbf{y}^{t} = \mathbf{H}*\mathbf{x}^{t} + \mathbf{v}^{t} $$

Nh∆∞ng vi·ªác bi·∫øt $\mathbf{y}^{t}$ s·∫Ω gi√∫p g√¨ cho l·∫ßn c·∫≠p nh·∫≠t ti·∫øp theo? X√©t bi·ªÉu th·ª©c:

$$p(x^{t}|y^{t}) = \frac{p(y^{t}|x^{t})p(x^{t})}{p(y^{t})} \hspace{1cm} (3)$$

Trong ƒë√≥:

$p(x^{t}|y^{t})$ 
l√† h√†m ph√¢n b·ªë x√°c su·∫•t c·ªßa 
$\mathbf{x}^{t}$ 
khi bi·∫øt 
$\mathbf{y}^{t}$

$p(y^{t}|x^{t})$ 
l√† h√†m ph√¢n b·ªë x√°c su·∫•t c·ªßa 
$\mathbf{y}^{t}$ 
khi bi·∫øt 
$\mathbf{x}^{t}$ 


$p(y^{t})$ v√† 
$p(x^{t})$ l·∫ßn l∆∞·ª£t l√† h√†m ph√¢n b·ªë x√°c su·∫•t c·ªßa 
$\mathbf{y}^{t}$ v√† 
$\mathbf{x}^{t}$ 

L√∫c n√†y vi·ªác c√≥ th√¥ng tin v·ªÅ 
$\mathbf{y}^{t}$ 
s·∫Ω gi√∫p ch√∫ng ta c·∫≠p nh·∫≠t l·∫°i h√†m ph√¢n b·ªë x√°c su·∫•t cho 
$\mathbf{x}^{t}$ th√¥ng qua 
$p(x^{t}|y^{t}).$ T·ª´ ƒë√≥ nh·ªØng quan s√°t ti·∫øp theo s·∫Ω mang ƒë·ªô ch√≠nh x√°c cao h∆°n.

# 2. H·ªá s·ªë Kalman

C√°c blog hi·ªán nay ƒëa s·ªë ƒë·ªÅu b·ªè qua ƒëi ph·∫ßn ch·ª©ng minh n√†y, nh∆∞ng m√¨nh s·∫Ω ch·ª©ng minh t·ª´ng b∆∞·ªõc cho b·∫°n th·∫•y t·ª´ ƒë√¢u m√† h·ªá s·ªë $Kalman$ xu·∫•t hi·ªán.

L∆∞u √Ω t·ª´ ƒë√¢y s·∫Ω n·ªìng n·∫∑c m√πi to√°n h·ªçc, h√£y ƒë·ªçc ch·∫≠m r√£i v√† c·∫©n th·∫≠n nh√©. Ch√∫ng ta s·∫Ω ch·ª©ng minh c√°c b√†i to√°n nh·ªè ƒë·ªÉ ra ƒë∆∞·ª£c h·ªá s·ªë Kalman ho√†n thi·ªán nh√©.

## 2.1 Schur Complement of matrix

C·ª• th·ªÉ "Schur Complement of matrix" bi·ªÉu di·ªÖn ma tr·∫≠n $\mathbf{M}^{-1}$ d·ª±a tr√™n 4 kh·ªëi ma tr·∫≠n n·∫±m trong ma tr·∫≠n $\mathbf{M}$ vu√¥ng.

X√©t ma tr·∫≠n $\mathbf{M}$ g·ªìm $2 \times 2$ c√°c kh·ªëi $matrix$:

$$\mathbf{M} = 
\begin{bmatrix}
\mathbf{A} & \mathbf{B} \\
\mathbf{B}^\mathsf{T} & \mathbf{D}
\end{bmatrix} \hspace{1cm} (4)$$

V·ªõi $\mathbf{A} \in \mathbb{R}^{p \times p}$, $\mathbf{B} \in \mathbb{R}^{p \times q}$ v√† $\mathbf{D} \in \mathbb{R}^{q \times q}$. C√≥ th·ªÉ suy ra k√≠ch th∆∞·ªõc c·ªßa $\mathbf{M}\in \mathbb{R}^{(p+q) \times (p+q)}$ 

***·ªû ƒë√¢y minh s·∫Ω ch·ª©ng minh cho tr∆∞·ªùng h·ª£p ƒë·∫∑t bi·ªát, c√≤n t·ªïng qu√°t b·∫°n h√£y thay $\mathbf{B}^{T}$ th√†nh $\mathbf{C}$ l√† ƒë∆∞·ª£c nh√©, c≈©ng c√≥ th·ªÉ xem nh∆∞ l√† b√†i t·∫≠p d√†nh cho b·∫°n ƒë·ªÉ quen v·ªõi ma tr·∫≠n h∆°n.***

ƒê·ªÉ gi·∫£i b√†i to√°n n√†y c≈©ng c·ª±c k·ª≥ ƒë∆°n gi·∫£n, h·∫≥n l√† b·∫°n ƒë√£ t·ª´ng gi·∫£i qua h·ªá ph∆∞∆°ng tr√¨nh b·∫±ng ma tr·∫≠n r·ªìi ph·∫£i kh√¥ng.

$$\mathbf{M} \times \mathbf{a} = \mathbf{b} \Rightarrow \mathbf{a} = \mathbf{M}^{-1} \times \mathbf{b} \hspace{1cm} (5)$$

***Note***: ·ªü ƒë√¢y $x$, $y$ l√† c√°c $vector \in \mathbb{R}^{(p+q)}$, v√† m·ªói khi $matrix^{-1}$ ta gi·∫£ s·ª≠ $matrix$ kh·∫£ ngh·ªãch

Cho:

$$\mathbf{a} = \begin{bmatrix}
\mathbf{x} \\
\mathbf{y}
\end{bmatrix};
\space
\mathbf{b} = \begin{bmatrix}
\mathbf{u} \\
\mathbf{v}
\end{bmatrix}
;\space a, u \in \mathbb{R}^{p} \space v√† \space b, v \in \mathbb{R}^{q}$$

T·ª´ $(4)$ v√† $(5)$ ta c√≥:

$$\mathbf{M} \times \mathbf{x} = \mathbf{y} \Leftrightarrow
\begin{bmatrix}
\mathbf{A} & \mathbf{B} \\
\mathbf{B}^\mathsf{T} & \mathbf{D}
\end{bmatrix}
\times 
\begin{bmatrix}
\mathbf{x} \\
\mathbf{y}
\end{bmatrix} = 
\begin{bmatrix}
\mathbf{u} \\
\mathbf{v}
\end{bmatrix}
\hspace{1cm} (6)$$

$$\Rightarrow 
\begin{bmatrix}
\mathbf{A} \mathbf{x} + \mathbf{B}y \\
\mathbf{B}^\mathsf{T}\mathbf{x} + \mathbf{D}\mathbf{y}
\end{bmatrix}=
\begin{bmatrix}
\mathbf{u} \\
\mathbf{v}
\end{bmatrix}
\hspace{1cm} (7)$$

T·ª´ $(7)$ ta ƒëi s·∫Ω t√¨m $\mathbf{x}$ v√† $\mathbf{y}$:

·ªû d√≤ng th·ª© hai c·ªßa $(7)$:

$$ \mathbf{y} = \mathbf{D}^{-1}(\mathbf{v}-\mathbf{B}^\mathsf{T}\mathbf{x}) \hspace{1cm} (8)$$

Th·∫ø $(8)$ v√†o d√≤ng th·ª© nh·∫•t c·ªßa $(7)$:

$$\mathbf{A} \mathbf{x} + \mathbf{B}\mathbf{D}^{-1}(\mathbf{v}-\mathbf{B}^\mathsf{T}\mathbf{x}) = \mathbf{u} \Leftrightarrow  (\mathbf{A} - \mathbf{B}\mathbf{D}^{-1}\mathbf{B}^\mathsf{T})\mathbf{x} = \mathbf{u} -  \mathbf{B}\mathbf{D}^{-1}\mathbf{v} \hspace{1cm} (9)$$

K·∫øt h·ª£p gi·ªØa $(8)$ v√† $(9)$ ta c√≥ ƒë∆∞·ª£c:

$$\mathbf{x} = (\mathbf{A} - \mathbf{B}\mathbf{D}^{-1}\mathbf{B}^\mathsf{T})^{-1}\mathbf{u} - (\mathbf{A} - \mathbf{B}\mathbf{D}^{-1}\mathbf{B}^\mathsf{T})^{-1}\mathbf{B}\mathbf{D}^{-1}\mathbf{v} \hspace{1cm} (10)$$

$$\mathbf{y=D^{-1}B^\mathsf{T}(A-BD^{-1}B^\mathsf{T})^{-1}u + (D^{-1} + 
D^{-1}B^\mathsf{T}(A-BD^{-1}B^\mathsf{T})^{-1}BD^{-1})v} \hspace{1cm} (11)$$

Ta ƒë·∫∑t $\mathbf{L = (A-BD^{-1}B^\mathsf{T})^{-1}}$ ƒë·ªÉ bi·ªÉu th·ª©c ƒë∆°n gi·∫£n h∆°n, ta vi·∫øt l·∫°i bi·ªÉu th·ª©c $(10)$ v√† $(11)$.

$$\mathbf{x = Lu - LBD^{-1}v}\hspace{1cm} (12)$$

$$\mathbf{y=D^{-1}B^{\mathsf{T}}Lu + (D^{-1} + 
D^{-1}B^\mathsf{T}LBD^{-1})v} \hspace{1cm} (13)$$

D·ªÖ d√†ng th·∫•y ƒë∆∞·ª£c:

$$
\begin{bmatrix}
\mathbf{x} \\
\mathbf{y}
\end{bmatrix} = 
\begin{bmatrix}
\mathbf{L} & \mathbf{-LBD^{-1}} \\
\mathbf{D^{-1}B^{\mathsf{T}}L} & \mathbf{D^{-1} + 
D^{-1}B^\mathsf{T}LBD^{-1}}
\end{bmatrix}
\begin{bmatrix}
\mathbf{u} \\
\mathbf{v}
\end{bmatrix}
\hspace{1cm} (14)$$

K·∫øt h·ª£p gi·ªØa $(5)$ v√† $(14)$, ta c√≥ ƒë∆∞·ª£c:

$$
\mathbf{M} = 
\begin{bmatrix}
\mathbf{A} & \mathbf{B} \\
\mathbf{B}^\mathsf{T} & \mathbf{D}
\end{bmatrix}^{-1} = 
\begin{bmatrix}
\mathbf{L} & \mathbf{-LBD^{-1}} \\
\mathbf{D^{-1}B^{\mathsf{T}}L} & \mathbf{D^{-1} + 
D^{-1}B^\mathsf{T}LBD^{-1}}
\end{bmatrix}
\space v·ªõi\space \mathbf{L = (A-BD^{-1}B^\mathsf{T})^{-1}} 
\hspace{1cm} (15)
$$

Th·∫ø l√† ta ƒë√£ xong v·ªõi vi·ªác bi·ªÉu di·ªÖn m·ªôt ma tr·∫≠n ngh·ªãch ƒë·∫£o c·ªßa ma tr·∫≠n vu√¥ng $\mathbf{M}$ d·ª±a v√†o 4 kh·ªëi ma tr·∫≠n con b√™n trong n√≥. B·∫°n c√≥ th·∫•y ma tr·∫≠n n√†y quen kh√¥ng, ƒë√∫ng r·ªìi ƒë·∫•y n√≥ ch√≠nh l√† ma tr·∫≠n covariance $\Sigma_z$.

V·ªõi:

$$
\mathbf{z} = 
\begin{bmatrix}
\mathbf{x} \\
\mathbf{y}
\end{bmatrix};\space \mathbf{x}\in \mathbb{R}^{p}, \space \mathbf{y}\in \mathbb{R}^{q}
$$

V√†:

$$
\mathbf{z} \thicksim \mathcal{N}(\mu_z,\Sigma_z)
\Leftrightarrow
\mathbf{z} \thicksim \mathcal{N}(
\begin{bmatrix}
\mu_x \\
\mu_y
\end{bmatrix}, 
\begin{bmatrix}
\Sigma_{xx} & \Sigma_{xy} \\
\Sigma_{yx} & \Sigma_{yy}
\end{bmatrix})
$$

V√¨ ƒë√¢y c≈©ng l√† m·ªôt b√†i to√°n kh√¥ng qu√° kh√≥ v√† c≈©ng kh√° d·ªÖ hi·ªÉu n·∫øu b·∫°n v·ªØng c√°c ki·∫øn th·ª©c v·ªÅ ma tr·∫≠n, ƒë·ªôc gi·∫£ c√≥ th·ªÉ ƒë·ªçc th√™m v·ªÅ [Multivariate Gaussian Distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) ƒë·ªÉ hi·ªÉu r√µ v·ªÅ ma tr·∫≠n covariance n√†y, v√¨ v·ªÅ sau ta s·∫Ω d√πng n√≥ nhi·ªÅu ƒë·∫•y.

## 2.2 Woodbury Matrix Identity

Woodbury Matrix Identity - ƒê·ªìng nh·∫•t th·ª©c ma tr·∫≠n Woodbury, ƒë·ªìng nh·∫•t th·ª©c gi√∫p t√≠nh to√°n bi·ªÉu th·ª©c 
$\mathbf{(A+UCV)^{-1}}$
nhanh ch√≥ng h∆°n khi ƒë√£ bi·∫øt $\mathbf{A^{-1}}$.

K√≠ch th∆∞·ªõc c·ªßa c√°c ma tr·∫≠n: 
$\mathbf{A} \in \mathbb{R}^{n \times n}$, $\mathbf{U, V} \in \mathbb{R}^{n \times k}$ v√† $\mathbf{C} \in \mathbb{R}^{k \times k}$ v√† c√¥ng th·ª©c c·ªßa n√≥ l√†:

$$\mathbf{(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}} \hspace{1cm} (16)
$$

üò±üò±üò± ***C√°i g√¨ th·∫ø n√†y, ch·∫≥ng ph·∫£i ph√≠a tr√™n ƒë√£ b·∫£o s·∫Ω gi√∫p t√≠nh to√°n nhanh h∆°n c∆° m√†, sao m√† l·∫°i d√†i ƒë·∫øn nh∆∞ th·∫ø n√†y!!!***

V·∫≠y ch√∫ng ta h√£y l·∫ßn l∆∞·ª£t ph√¢n t√≠ch chi ph√≠ t√≠nh to√°n c·ªßa bi·ªÉu th·ª©c 
$\mathbf{(A+UCV)^{-1}}$ 
khi ch∆∞a √°p d·ª•ng "ƒê·ªìng nh·∫•t th·ª©c Woodbury" nh√©.

- C·ª© m·ªói ph√©p c·ªông/tr·ª´ gi·ªØa hai ma tr·∫≠n c√≥ kh√≠ch th∆∞·ªõc $a \times b$ v√† $a \times b$ c√≥ chi ph√≠ l√† $a \times b$ 

- C·ª© m·ªói ph√©p nh√¢n gi·ªØa hai ma tr·∫≠n c√≥ kh√≠ch th∆∞·ªõc $a \times b$ v√† $b \times c$ c√≥ chi ph√≠ l√† $a \times b \times c$
- Ngh·ªãch ƒë·∫£o ma tr·∫≠n vu√¥ng $a \times a$ s·∫Ω c√≥ chi ph√≠ l√† $a^{3}$

$\mathbf{(A+UCV)^{-1}}$  bao g·ªìm 2 ph√©p nh√¢n, 1 ph√©p c·ªông v√† 1 ph√©p ngh·ªãch ƒë·∫£o. T·ªïng chi ph√≠ t√≠nh to√°n l√∫c n√†y s·∫Ω l√†:

$$\mathbf{n \times k \times k + n \times k \times n + n \times n + n \times n \times n = n^{3} + n^{2}k + nk^{2}}$$

$\mathbf{A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}}$ 
bao g·ªìm 6 ph√©p nh√¢n, 2 ph√©p c·ªông/tr·ª´ v√† 2 ph√©p ngh·ªãch ƒë·∫£o c·ªßa 
$\mathbf{C^{-1}}$ 
"***ta ƒë√£ gi·∫£ s·ª≠ bi·∫øt tr∆∞·ªõc
$\mathbf{A^{-1}}$***". L√∫c n√†y chi ph√≠ t√≠nh to√°n l√†:

$$\mathbf{k^{3} + 2k^{2}n + 4n^{2}k + k^{2}  + n^{2}}$$

R√µ r√†ng, b·∫≠c 3 c·ªßa ch√∫ng ta l√∫c n√†y ƒë√£ ƒë∆∞a v·ªÅ cho 
$\mathbf{k}$ 
thay v√¨ l√† 
$\mathbf{n}$
nh∆∞ l√∫c tr∆∞·ªõc, v√† n·∫øu $\mathbf{n \gg k}$ th√¨ th·∫≠t s·ª±, t·ªëc ƒë·ªô t√≠nh to√°n l√∫c n√†y gi·∫£m ƒëi r·∫•t nhi·ªÅu l·∫ßn. H√¨nh b√™n d∆∞·ªõi m√¥ t·∫£ s·ª± tƒÉng tr∆∞·ªüng c·ªßa $\mathbf{n}$, k√Ω hi·ªáu trong h√¨nh s·∫Ω l√† $\mathbf{p}$.

[![Woodbury performance](/assets\images\Kalman_Filter\woodbury.png)](https://stackoverflow.com/questions/53564529/woodbury-identity-for-fast-matrix-inversion-slower-than-expected)

***Note: h√£y t√≠nh to√°n 6 ph√©p nh√¢n th√¥ng minh, ƒë·ª´ng ƒë·ªÉ b·ªã d√≠nh v√†o ph√©p nh√¢n $\mathbf{n^{3}}$ nh√©. C√≤n m·ªôt ƒëi·ªÅu n·ªØa, "ƒê·ªìng nh·∫•t th·ª©c ma tr·∫≠n Woodbury" c√≤n c√≥ th·ªÉ √°p d·ª•ng cho tr∆∞·ªùng h·ª£p ma tr·∫≠n $\mathbf{A}$ l√† ma tr·∫≠n tam gi√°c.***

V·∫≠y ƒëi·ªÅu n√†y c√≥ nghƒ©a g√¨ ü§îü§îü§î, b·∫°n c√≥ ƒë·ªÉ √Ω th·∫•y 
$\mathbf{(A+UCV)^{-1}}$ 
gi·ªëng v·ªõi ma tr·∫≠n n√†o c·ªßa ch√∫ng ta kh√¥ng?

B·∫°n ƒëo√°n ƒë√∫ng r·ªìi ƒë·∫•y, ƒë√≥ ch√≠nh l√† ma tr·∫≠n 
$\mathbf{L = (A-BD^{-1}B^\mathsf{T})^{-1}}$
. Ch√† ch√†, m·ªçi th·ª© c√≥ v·∫ª work v·ªõi nhau r·ªìi ch·ª©.
H√£y ch·ªù ƒë·ª£i b√≠ m·∫≠t ƒë∆∞·ª£c khai ph√° ·ªü m·ª•c ti·∫øp theo nh√©.

N√†o h√£y c√πng m√¨nh ch·ª©ng minh v·ªÅ "ƒê·ªìng nh·∫•t th·ª©c ma tr·∫≠n Woodbury" nh√©.

Ta s·∫Ω b·∫Øt ƒë·∫ßu t·ª´ hai bi·ªÉu th·ª©c c∆° b·∫£n sau:

$$\mathbf{(I+P)^{-1} = (I+P^{-1})(I+P-P) = I - (I+P)^{-1}P} \hspace{1cm} (*)$$

$$\mathbf{P + PQP = P(I + QP) = (I + PQ)P}$$

$$
Suy\space ra:\space \mathbf{(I + PQ)^{-1}P = P(I + QP)^{-1}}
\hspace{1cm} (**)
$$

T·ª´ ƒë√≥ ta khai tri·ªÉn bi·ªÉu th·ª©c:

$$
\begin{equation*}
\begin{split}
\mathbf{(A+UCV)^{-1}} & = \mathbf{(A[I+A^{-1}UCV])^{-1}} \\
& = \mathbf{\left[I +A^{-1}UCV\right]^{-1}A^{-1}} \\
& = \mathbf{\left[I - (I+A^{-1}UCV)^{-1}A^{-1}UCV\right]A^{-1}},\space \text{d√πng bi·ªÉu th·ª©c (*)}\space P = A^{-1}UCV\\
& = \mathbf{A^{-1} - (I+A^{-1}UCV)^{-1}A^{-1}UCVA^{-1}} \\
& = \mathbf{A^{-1} - A^{-1}(I+UCVA^{-1})^{-1}UCVA^{-1}}, \space \text{d√πng bi·ªÉu th·ª©c (**)}\space P = A^{-1}, Q = UCV\\
& = \mathbf{A^{-1} - A^{-1}U(I+CVA^{-1}U)^{-1}CVA^{-1}}, \space \text{d√πng bi·ªÉu th·ª©c (**)}\space P = U, Q = CVA^{-1}, \space\\
& = \mathbf{A^{-1} - A^{-1}U(CC^{-1}+CVA^{-1}U)^{-1}CVA^{-1}}, \space \text{gi·∫£ s·ª≠ C kh·∫£ ngh·ªãch}\\
& = \mathbf{A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1}C^{-1}CVA^{-1}}, \space \text{l·∫•y C l√†m nh√¢n t·ª≠ chung}\\
& = \mathbf{A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}}, \space \text{ƒëi·ªÅu ph·∫£i ch·ª©ng minh}\\
\end{split}
\end{equation*}$$

## 2.3 Conditional Gaussian distributions

ƒê√¢y ch√≠nh l√† ph·∫ßn ch√≠nh c·ªßa ph·∫ßn gi·∫£i th√≠ch h·ªá s·ªë Kalman. C√°c b·∫°n h√£y t·∫≠p trung theo d√µi nh√©.

Ch√∫ng ta ƒë√£ ph√¢n t√≠ch ·ªü tr√™n v·ªÅ $p(x^{t}|y^{t})$, l√† h√†m ph√¢n ph·ªëi x√°c su·∫•t s·∫Ω gi√∫p ta c·∫≠p nh·∫≠t l·∫°i ni·ªÅm tin v·ªÅ $x^{t}$ khi ƒë√£ bi·∫øt $y^{t}$.

L√∫c n√†y ta x√©t vector:

$$
\mathbf{z} = 
\begin{bmatrix}
\mathbf{x} \\
\mathbf{y}
\end{bmatrix};\space \mathbf{x}\in \mathbb{R}^{p}, \space \mathbf{y}\in \mathbb{R}^{q}
$$

V√†:

$$
\mathbf{z} \thicksim \mathcal{N}(\mu_z,\Sigma_z)
\Leftrightarrow
\mathbf{z} \thicksim \mathcal{N}(
\begin{bmatrix}
\mu_x \\
\mu_y
\end{bmatrix}, 
\begin{bmatrix}
\Sigma_{xx} & \Sigma_{xy} \\
\Sigma_{yx} & \Sigma_{yy}
\end{bmatrix})
$$

D√†nh cho nh·ªØng b·∫°n ch∆∞a bi·∫øt v·ªÅ ma tr·∫≠n covariance n√†y c√≥ th·ªÉ ƒë·ªçc th√™m ·ªü ƒë√¢y [Multivariate Gaussian Distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution). ƒê·∫∑c t√¨nh c·ªßa ma tr·∫≠n covariance n√†y ch√≠nh l√†:

$$$$